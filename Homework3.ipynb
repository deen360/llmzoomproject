{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f89dff-87da-456b-94da-65935ca93c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U minsearch qdrant_client\n",
    "#!pip install sentence_transformers\n",
    "#!pip install rouge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a8c2b60-b742-40c6-bf1e-d877a2040e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import requests\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "import minsearch\n",
    "from tqdm.auto import tqdm\n",
    "from minsearch import VectorSearch\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.http import models\n",
    "from qdrant_client import models, QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rouge import Rouge\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffea9e0a-5bd5-4fa9-b461-7ef62b2ad1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url).json()\n",
    "\n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a2e648-b80c-4fff-865e-129981701327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd378187-d39b-4728-a6f3-a669bae45320",
   "metadata": {},
   "source": [
    "#### **Q1. Minsearch text**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a8d0f3-afe8-42cc-a7df-b1b34141d210",
   "metadata": {},
   "source": [
    "**index the document and fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3db12ab-39cb-40af-966d-fa259a195f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\", \"id\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413ab3af-c876-4b78-a8b0-9a238616ecc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x72105528a7b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459a7b06-7326-49da-b9ce-e0484eaa69d5",
   "metadata": {},
   "source": [
    "**define the search function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c556db6-33d4-4be1-a5dd-335cb4d38480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, course):\n",
    "    boost = {'question': 1.5, 'section': 0.1}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': course},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c6cb2d-81b0-4438-9706-9082cc99430d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcf2870d-7e2a-4322-8b30-9722dad91818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e7fb3b8e2d4c2883a112e58d6d8981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize an empty list to store relevance information for each query\n",
    "relevance_total = []\n",
    "\n",
    "# Iterate through each question in the ground_truth dataset, with a progress bar\n",
    "for q in tqdm(ground_truth):\n",
    "    # Get the document ID of the correct answer from the ground truth\n",
    "    doc_id = q['document']\n",
    "    \n",
    "    # Perform a search using the question text and course context\n",
    "    results = minsearch_search(query=q['question'], course=q['course'])\n",
    "    \n",
    "    # Create a list of boolean values indicating whether each retrieved document\n",
    "    # matches the correct document ID (i.e., is relevant or not)\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    \n",
    "    # Add the relevance list to the overall results\n",
    "    relevance_total.append(relevance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7c46fe-1661-495d-a681-b56e622f918e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relevance_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ca2405-854f-4a0c-9f83-f134de546d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit rate:  0.848714069591528\n"
     ]
    }
   ],
   "source": [
    "hit = hit_rate(relevance_total)\n",
    "print(\"hit rate: \",hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9fdeb3-9f24-42dc-a3c3-e0301ec75dd2",
   "metadata": {},
   "source": [
    "#### **Q2. Vector search for question**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c148b4-ef84-4f9f-b259-1bfe5a5157fb",
   "metadata": {},
   "source": [
    "**Extract the questions and embed them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a064e42-53a0-4784-bb7c-c1a37c4c60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store question texts\n",
    "texts = []\n",
    "\n",
    "# Extract the 'question' field from each document and add it to the list\n",
    "for doc in documents:\n",
    "    t = doc['question']\n",
    "    texts.append(t)\n",
    "\n",
    "# Create a pipeline that first vectorizes the text using TF-IDF,\n",
    "# then reduces the dimensionality using Truncated SVD (a form of LSA)\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),           # Convert text to TF-IDF vectors, ignoring rare terms (appearing in fewer than 3 documents)\n",
    "    TruncatedSVD(n_components=128, random_state=1)  # Reduce TF-IDF matrix to 128 dimensions for compact representation\n",
    ")\n",
    "\n",
    "# Fit the pipeline to the question texts and transform them into vector representations\n",
    "X = pipeline.fit_transform(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c7d343b-0315-459d-b11b-1a0542c91b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x7210545dc2f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector search index with keyword-based filtering on the 'course' field.\n",
    "# This allows you to later filter search results by course if needed.\n",
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "\n",
    "# Fit (index) the vector search model with the vector representations (X)\n",
    "# and the original documents (used for metadata and keyword filtering).\n",
    "vindex.fit(X, documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6824ea68-59e3-4fb7-9a0f-cee5740654cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query, course):\n",
    "    \n",
    "    query_vec = pipeline.transform([query])\n",
    "    \n",
    "    results = vindex.search(\n",
    "        query_vec, \n",
    "        filter_dict={'course': course},\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "368e0332-d4c4-463c-9a25-ebbf3b9522e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03534243c0df4252b446b8ec1586cf8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize an empty list to store relevance information for each query\n",
    "relevance_vector_total = []\n",
    "\n",
    "# Iterate through each question in the ground_truth dataset, with a progress bar\n",
    "for q in tqdm(ground_truth):\n",
    "    # Get the document ID of the correct answer from the ground truth\n",
    "    doc_id = q['document']\n",
    "    \n",
    "    # Perform a search using the question text and course context\n",
    "    results = vector_search(query=q['question'], course=q['course'])\n",
    "    \n",
    "    # Create a list of boolean values indicating whether each retrieved document\n",
    "    # matches the correct document ID (i.e., is relevant or not)\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    \n",
    "    # Add the relevance list to the overall results\n",
    "    relevance_vector_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fd76cf9-811c-4766-a80b-c61c3fe4f5cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr rate: 0.3571284489590088\n"
     ]
    }
   ],
   "source": [
    "mrr_rate = mrr(relevance_vector_total)\n",
    "print(\"mrr rate:\", mrr_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf338439-d027-483c-9553-4a595c9b469d",
   "metadata": {},
   "source": [
    "#### **Q3. Vector search for question and answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b660b0e-9848-405f-84c2-cfcdc4987b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question'] + ' ' + doc['text']\n",
    "    texts.append(t)\n",
    "\n",
    "# Create a pipeline that first vectorizes the text using TF-IDF,\n",
    "# then reduces the dimensionality using Truncated SVD (a form of LSA)\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),           # Convert text to TF-IDF vectors, ignoring rare terms (appearing in fewer than 3 documents)\n",
    "    TruncatedSVD(n_components=128, random_state=1)  # Reduce TF-IDF matrix to 128 dimensions for compact representation\n",
    ")\n",
    "\n",
    "# Fit the pipeline to the question texts and transform them into vector representations\n",
    "X = pipeline.fit_transform(texts)\n",
    "\n",
    "\n",
    "# Create a vector search index with keyword-based filtering on the 'course' field.\n",
    "# This allows you to later filter search results by course if needed.\n",
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "\n",
    "# Fit (index) the vector search model with the vector representations (X)\n",
    "# and the original documents (used for metadata and keyword filtering).\n",
    "vindex.fit(X, documents)\n",
    "\n",
    "def vector_search(query, course):\n",
    "    \n",
    "    query_vec = pipeline.transform([query])\n",
    "    \n",
    "    results = vindex.search(\n",
    "        query_vec, \n",
    "        filter_dict={'course': course},\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3502c7a6-ebaf-49ac-9938-3987b8c0def3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b675d077ae9e4d3caf4c117f197401b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize an empty list to store relevance information for each query\n",
    "relevance_vector_total = []\n",
    "\n",
    "# Iterate through each question in the ground_truth dataset, with a progress bar\n",
    "for q in tqdm(ground_truth):\n",
    "    # Get the document ID of the correct answer from the ground truth\n",
    "    doc_id = q['document']\n",
    "    \n",
    "    # Perform a search using the question text and course context\n",
    "    results = vector_search(query=q['question'], course=q['course'])\n",
    "    \n",
    "    # Create a list of boolean values indicating whether each retrieved document\n",
    "    # matches the correct document ID (i.e., is relevant or not)\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    \n",
    "    # Add the relevance list to the overall results\n",
    "    relevance_vector_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12f3ce87-5de7-479c-ba64-32e2c4b22069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit rate:  0.8210503566025502\n"
     ]
    }
   ],
   "source": [
    "hit = hit_rate(relevance_vector_total)\n",
    "print(\"hit rate: \",hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d1796-359b-4c01-aa83-e9b77458fb24",
   "metadata": {},
   "source": [
    "#### **Q4. Qdrant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21dfe46b-dd74-4930-9358-a5ac7ab27771",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd59f36-6b09-4ad2-bd06-49cf3b40ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = TextEmbedding('jinaai/jina-embeddings-v2-small-en')\n",
    "collection_name = \"homework\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cccedd5a-0c6e-4b65-ab9d-d611a78f2acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload points (vectors with associated payloads) to a specified Qdrant collection\n",
    "client.upload_points(\n",
    "    collection_name=collection_name,  # The name of the collection to upload the points to\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=idx,  # Unique ID for each point, using its index in the documents list\n",
    "            vector=list(  # Convert the generator returned by `embed()` into a list\n",
    "                embedding_model.embed(\n",
    "                    doc['question'] + ' ' + doc['text']  # Concatenate question and text to create the embedding input\n",
    "                )\n",
    "            )[0].tolist(),  # Get the first embedding (assuming one per input) and convert it to a plain Python list\n",
    "            payload=doc  # Attach the original document as metadata (payload)\n",
    "        )\n",
    "        for idx, doc in enumerate(documents)  # Loop over all documents with their index\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "233f5ae9-dfd2-4c80-8fe8-2511772c94c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qdrant_search(query, course):\n",
    "    \n",
    "    results = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query = list(embedding_model.embed(query))[0],\n",
    "        query_filter=models.Filter(\n",
    "        must=[models.FieldCondition(key=\"course\", match=models.MatchValue(value=course))]\n",
    "        ),\n",
    "        limit=5,\n",
    "    ).points\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4355ce6e-25fb-4a66-9d1e-20151dc54292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831ccc65517c4cb9983d3a59a1f7367f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize an empty list to store relevance information for each query\n",
    "relevance_vector_qdrant = []\n",
    "\n",
    "# Iterate through each question in the ground_truth dataset, with a progress bar\n",
    "for q in tqdm(ground_truth):\n",
    "    # Get the document ID of the correct answer from the ground truth\n",
    "    doc_id = q['document']\n",
    "    \n",
    "    # Perform a search using the question text and course context\n",
    "    results = qdrant_search(query=q['question'], course=q['course'])\n",
    "    \n",
    "    # Create a list of boolean values indicating whether each retrieved document\n",
    "    # matches the correct document ID (i.e., is relevant or not)\n",
    "    relevance = [d.payload['id'] == doc_id for d in results]\n",
    " \n",
    "    # Add the relevance list to the overall results\n",
    "    relevance_vector_qdrant.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b441bd5-5011-4dc9-9ba6-bedc28696be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr rate: 0.8517722066133576\n"
     ]
    }
   ],
   "source": [
    "mrr_rate2 = mrr(relevance_vector_qdrant)\n",
    "print(\"mrr rate:\", mrr_rate2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c97e0-2a63-46ae-81ce-2c07c9574648",
   "metadata": {},
   "source": [
    "#### **Q5. Cosine simiarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b18349-b54b-4d99-b8e3-e1222eedf1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_url = url_prefix + 'rag_evaluation/data/results-gpt4o-mini.csv'\n",
    "df_results = pd.read_csv(results_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b0590c-bf62-4781-bbe3-b20491a99586",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0285e066-f63d-4f70-b921-430c7740feb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline.fit(df_results.answer_llm + ' ' + df_results.answer_orig + ' ' + df_results.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61d2fb9c-4723-4e92-a1ae-03ba8a3bb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(pipeline, record):\n",
    "    answer_orig = record['answer_orig']\n",
    "    answer_llm = record['answer_llm']\n",
    "\n",
    "    v_llm = pipeline.transform([answer_llm])[0]\n",
    "    v_orig = pipeline.transform([answer_orig])[0]\n",
    "\n",
    "    return v_llm.dot(v_orig) / (np.linalg.norm(v_llm) * np.linalg.norm(v_orig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0b56958-c250-4dbc-a6fd-bad7557072c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a743f1e6dadb4a67b95bdab6f9216cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarity = []\n",
    "\n",
    "for _, record in tqdm(df_results.iterrows(), total=len(df_results)):\n",
    "    sim = compute_similarity(pipeline, record)\n",
    "    similarity.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3effa28-f24b-4072-a83f-c22aa51f327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "098e4794-1965-40ef-8300-91d32338bc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.841584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.173737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.079093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.806927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.905812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.950711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.996457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1830.000000\n",
       "mean      0.841584\n",
       "std       0.173737\n",
       "min       0.079093\n",
       "25%       0.806927\n",
       "50%       0.905812\n",
       "75%       0.950711\n",
       "max       0.996457"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a875ed-584a-4fc4-8e3c-073c5f1ae10c",
   "metadata": {},
   "source": [
    "#### **Q6. Rouge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3396ce7-2aad-41b0-b10e-863c30d5da9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scorer = Rouge()\n",
    "r = df_results.iloc[10]\n",
    "scores = rouge_scorer.get_scores(r.answer_llm, r.answer_orig)[0]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91abdb20-dc80-443d-b501-277ef74d23b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps, refs = zip(*[\n",
    "    (row[\"answer_llm\"], row[\"answer_orig\"])\n",
    "    for _, row in df_results.iterrows()\n",
    "])\n",
    "hyps = list(hyps)\n",
    "refs = list(refs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bc6150a-1335-4323-84ce-3a8ba78c524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "#scores = rouge.get_scores(hyps, refs)\n",
    "scores = rouge.get_scores(hyps, refs, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf23d1c8-4a14-4999-92b4-34102bb7ce04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3516946452113944"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['rouge-1']['f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9244000e-8866-453f-971e-09be26bb9fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
